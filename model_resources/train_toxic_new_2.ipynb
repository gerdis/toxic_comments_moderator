{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "import logging\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data (toxic comments dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\gande\\\\Desktop\\\\ProjektKlassifikation\\\\toxic_comments_data\\\\train.csv', \n",
    "                   sep=',', header=0, quotechar= '\"', quoting=csv.QUOTE_MINIMAL, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = 'C:\\\\Users\\\\gande\\\\Desktop\\\\ProjektKlassifikation\\\\toxic_comments_data\\\\test.csv'\n",
    "test_df = pd.read_csv(testpath, sep=',', header=0, quotechar= '\"', quoting=csv.QUOTE_MINIMAL, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabelpath = 'C:\\\\Users\\\\gande\\\\Desktop\\\\ProjektKlassifikation\\\\toxic_comments_data\\\\test_labels.csv'\n",
    "test_label_df = pd.read_csv(testlabelpath, sep=',', header=0, quotechar= '\"', quoting=csv.QUOTE_MINIMAL,\n",
    "                            encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove comments with [-1, -1, -1, -1, -1, -1] labeling from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_minus_ones_comments(comments_df, label_df):\n",
    "    \n",
    "    for index, row in label_df.iterrows():\n",
    "        rowlabels = [row['toxic'], row['severe_toxic'],\n",
    "                     row['obscene'], row['threat'],\n",
    "                     row['insult'], row['identity_hate']]\n",
    "        if -1 in rowlabels:\n",
    "            comments_df = comments_df.drop([index], axis=0)\n",
    "            \n",
    "    return comments_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_minus_ones_labels(label_df):\n",
    "    for index, row in label_df.iterrows():\n",
    "        rowlabels = [row['toxic'], row['severe_toxic'],\n",
    "                     row['obscene'], row['threat'],\n",
    "                     row['insult'], row['identity_hate']]\n",
    "        \n",
    "        if -1 in rowlabels:\n",
    "            label_df = label_df.drop([index], axis=0)\n",
    "            \n",
    "    return label_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = drop_minus_ones_comments(test_df[0:70000], test_label_df[0:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = drop_minus_ones_comments(test_df[70000:], test_label_df[70000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_df1 = drop_minus_ones_labels(test_label_df[0:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_df2 = drop_minus_ones_labels(test_label_df[70000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df1, test_df2])\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_label_df = pd.concat([test_label_df1, test_label_df2])\n",
    "test_label_df = test_label_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y_train = [[row[l] for l in labels] for index, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [[row[l] for l in labels] for index, row in test_label_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \n",
    "    \"\"\"remove punctuation, \n",
    "    convert to lowercase\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    for index, row in df.iterrows():\n",
    "        corpus.append([re.sub(\"[^a-zA-Z']\", ' ', \n",
    "                      row['comment_text'].lower())])\n",
    "        \n",
    "    return np.ravel(corpus).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = prepare_data(data)\n",
    "X = traindata\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_labels = [p for p in zip(X, y)]\n",
    "#traindata_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_testdata = prepare_data(test_df)\n",
    "prepared_testlabels = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Google's 300-dimensional vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\gande\\\\GoogleNews-vectors-negative300.bin'\n",
    "googlevecs = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test dataset in validation and test data (stratified split with k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following algorithm was implemented following the suggestions of Sechidis et al. (2011)* for stratified sampling of multi-label data. \n",
    "\n",
    "\\* see README for full reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_stratification(dataset, datalabels, labelnames, k=6):\n",
    "    \n",
    "    #put all negative samples in extra list\n",
    "    all_neg = []\n",
    "    data_and_labels = [x for x in zip(dataset, datalabels)]\n",
    "    \n",
    "    for d in data_and_labels:\n",
    "        if not np.any(d[1]):\n",
    "            all_neg.append(d)\n",
    "    for f in all_neg:\n",
    "        data_and_labels.remove(f)\n",
    "    dataset = [z[0] for z in data_and_labels]\n",
    "    datalabels = [z[1] for z in data_and_labels]\n",
    "        \n",
    "    #build dictionary that will contain actual subsets\n",
    "    actual_subsets = dict()\n",
    "    for n in range(1,k+1):\n",
    "        actual_subsets[n] = []\n",
    "    \n",
    "    #Calculate desired number of samples per subset\n",
    "    subsets = dict()\n",
    "    proportion = 1/k\n",
    "    subset_size = len(dataset) * proportion\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        \n",
    "        subsets[i] = dict()\n",
    "        subsets[i]['current_size'] = subset_size\n",
    "        \n",
    "    #Calculate desired number of samples of each label in each subset\n",
    "    current_labelcount = dict()\n",
    "    for l in labelnames:\n",
    "        #Find the examples of each label in the initial set\n",
    "        labelindex = labelnames.index(l)\n",
    "        total_count_label = len([labelset[labelindex] for labelset in datalabels if labelset[labelindex]])\n",
    "        current_labelcount[l] = total_count_label\n",
    "        for k in subsets.keys():\n",
    "            #we want the same number in all subsets if possible\n",
    "            subsets[k][l] = proportion * total_count_label\n",
    "            \n",
    "    while len(dataset) > 0:\n",
    "        #Find label with the fewest (but at least one) remaining samples, \n",
    "        nonempty = {label:count for (label, count) in current_labelcount.items() if current_labelcount[label] > 0}\n",
    "        nonzero_counts = np.array(list(nonempty.values()))\n",
    "        try:\n",
    "            sparsest = np.argmin(nonzero_counts)\n",
    "            number = np.min(nonzero_counts)\n",
    "            name_of_label = list(nonempty.keys())[sparsest]\n",
    "            index_of_label = list(current_labelcount.keys()).index(name_of_label)\n",
    "            #Then, for each sample (x, Y ) with this label, select\n",
    "            #an appropriate subset for distribution.\n",
    "            distributed_pairs = []\n",
    "            for idx, s in enumerate(dataset):\n",
    "                if datalabels[idx][index_of_label] == 1:\n",
    "                    #Find the subset with the largest number of desired samples for this label\n",
    "                    desired_numbers_label = [subsets[k][name_of_label] for k in subsets.keys()]\n",
    "                    max_desired_number = np.max(desired_numbers_label)\n",
    "                    indices_maxima = np.where(desired_numbers_label == max_desired_number)[0]\n",
    "                    howmany = len(indices_maxima)\n",
    "                    if howmany == 1:\n",
    "                        index_subset = np.argmax(desired_numbers_label)\n",
    "                        put_in_subset = list(subsets.keys())[index_subset]\n",
    "                    else:\n",
    "                        #among the tying subsets, the one with the \n",
    "                        #highest number of desired examples gets selected\n",
    "                        cand = [key for key in subsets.keys() if list(subsets.keys()).index(key) in indices_maxima]\n",
    "                        desired_numbers_total = [subsets[j]['current_size'] for j in cand]\n",
    "                        max_desired_total = np.max(desired_numbers_total)\n",
    "                        indices_maxima_total = np.where(desired_numbers_total == max_desired_total)[0]\n",
    "                        howmany_total = len(indices_maxima_total)\n",
    "                        if howmany_total == 1:\n",
    "                            index_subset_in_cand = np.argmax(desired_numbers_total)\n",
    "                            put_in_subset = cand[index_subset_in_cand]\n",
    "                        else:\n",
    "                            #pick random element of cand\n",
    "                            put_in_subset = random.choice(cand)\n",
    "                    #Once the appropriate subset is selected, we add the sample (x, Y ) \n",
    "                    #to it and remove it from D.\n",
    "                    actual_subsets[put_in_subset].append((s, datalabels[idx]))\n",
    "                    distributed_pairs.append((s, datalabels[idx]))\n",
    "                    #At the end of the iteration, we decrement the total number \n",
    "                    #of desired examples for subset m, cm\n",
    "                    subsets[put_in_subset]['current_size'] = subsets[put_in_subset]['current_size'] - 1\n",
    "                    #decrement the number of desired samples \n",
    "                    #for each label of this example in chosen subset\n",
    "                    for labelind, lab in enumerate(datalabels[idx]):\n",
    "                        if lab == 1:\n",
    "                            name = labelnames[labelind]\n",
    "                            subsets[put_in_subset][name] = subsets[put_in_subset][name] - 1\n",
    "                            current_labelcount[name] = current_labelcount[name] - 1\n",
    "                        \n",
    "            data_and_labels = [x for x in zip(dataset, datalabels)]\n",
    "            for p in distributed_pairs:\n",
    "                data_and_labels.remove(p)\n",
    "            dataset = [z[0] for z in data_and_labels]\n",
    "            datalabels = [z[1] for z in data_and_labels]\n",
    "        \n",
    "        except ValueError:\n",
    "            break\n",
    "            \n",
    "    #Samples that are not annotated with any label are distributed so as to \n",
    "    #balance the desired number of examples at each subset. \n",
    "    negs_per_subset = math.floor(len(all_neg) * proportion)\n",
    "    if negs_per_subset:\n",
    "        for everykey in actual_subsets.keys():\n",
    "            add_negatives = random.sample(all_neg,  negs_per_subset)\n",
    "            actual_subsets[everykey].extend(add_negatives)\n",
    "        \n",
    "    #SHUFFLE ACTUAL SUBSETS\n",
    "    for v in actual_subsets.values():\n",
    "        random.shuffle(v)\n",
    "    \n",
    "    return actual_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val = iterative_stratification(prepared_testdata, prepared_testlabels, labelnames=labels, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'toxic': 3045,\n",
       "  'severe_toxic': 183,\n",
       "  'obscene': 1845,\n",
       "  'threat': 106,\n",
       "  'insult': 1714,\n",
       "  'identity_hate': 356,\n",
       "  'total': 31982},\n",
       " 2: {'toxic': 3045,\n",
       "  'severe_toxic': 184,\n",
       "  'obscene': 1846,\n",
       "  'threat': 105,\n",
       "  'insult': 1713,\n",
       "  'identity_hate': 356,\n",
       "  'total': 31995}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check distribution\n",
    "distribution = dict()\n",
    "for key in test_val.keys():\n",
    "    distribution[key] = dict()\n",
    "    for l in labels:\n",
    "        labelindex = labels.index(l)\n",
    "        number = np.count_nonzero([x[1][labelindex] for x in test_val[key]])\n",
    "        distribution[key][l] = number\n",
    "    distribution[key]['total'] = len(test_val[key])\n",
    "distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize + lemmatize words and convert to vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_w2v_nonstrat(x, model, lemmatize=True, pretrained=googlevecs):  \n",
    "    \n",
    "    datalist = []\n",
    "\n",
    "    for pair in x:        \n",
    "        tk = TweetTokenizer()\n",
    "        splitcomment = tk.tokenize(pair[0])        \n",
    "        commentlist = []\n",
    "\n",
    "        if lemmatize:\n",
    "            verbs_lemmatized = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in splitcomment]\n",
    "            splitcomment = [wordnet_lemmatizer.lemmatize(word, pos='n') for word in verbs_lemmatized]\n",
    "\n",
    "        for word in splitcomment:\n",
    "            try:\n",
    "                commentlist.append(model[word])\n",
    "\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    commentlist.append(pretrained[word])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "        if len(commentlist) != 0:\n",
    "            commentarr = np.array(commentlist)\n",
    "            datalist.append((commentarr, pair[1]))\n",
    "            \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_labels = convert_to_w2v_nonstrat(traindata_labels, googlevecs, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_labels = convert_to_w2v_nonstrat(test_val[1], googlevecs, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdata_labels = convert_to_w2v_nonstrat(test_val[2], googlevecs, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input for Keras neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = np.array([pair[0] for pair in traindata_labels], dtype=object)\n",
    "train_labels = np.array([pair[1] for pair in traindata_labels])\n",
    "\n",
    "val_text = np.array([pair[0] for pair in valdata_labels], dtype=object)\n",
    "val_labels = np.array([pair[1] for pair in valdata_labels])\n",
    "\n",
    "test_text = np.array([pair[0] for pair in testdata_labels], dtype=object)\n",
    "test_labels = np.array([pair[1] for pair in testdata_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate, Dropout\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_recall', \n",
    "                                                 mode=\"max\", patience=2, \n",
    "                                                 restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "159528/159528 [==============================] - 1206s 8ms/step - loss: 0.0655 - precision: 0.7791 - recall: 0.5388 - val_loss: 0.0695 - val_precision: 0.6734 - val_recall: 0.5438\n",
      "Epoch 2/12\n",
      "159528/159528 [==============================] - 1211s 8ms/step - loss: 0.0519 - precision: 0.7981 - recall: 0.6359 - val_loss: 0.0658 - val_precision: 0.7022 - val_recall: 0.5384\n",
      "Epoch 3/12\n",
      "159528/159528 [==============================] - 1162s 7ms/step - loss: 0.0482 - precision: 0.8108 - recall: 0.6585 - val_loss: 0.0629 - val_precision: 0.7108 - val_recall: 0.5631\n",
      "Epoch 4/12\n",
      "159528/159528 [==============================] - 1132s 7ms/step - loss: 0.0454 - precision: 0.8167 - recall: 0.6760 - val_loss: 0.0621 - val_precision: 0.6925 - val_recall: 0.6048\n",
      "Epoch 5/12\n",
      "159528/159528 [==============================] - 1184s 7ms/step - loss: 0.0433 - precision: 0.8219 - recall: 0.6936 - val_loss: 0.0613 - val_precision: 0.7153 - val_recall: 0.5875\n",
      "Epoch 6/12\n",
      "159528/159528 [==============================] - 1223s 8ms/step - loss: 0.0419 - precision: 0.8262 - recall: 0.7058 - val_loss: 0.0623 - val_precision: 0.6791 - val_recall: 0.6303\n",
      "Epoch 7/12\n",
      "159528/159528 [==============================] - 1183s 7ms/step - loss: 0.0403 - precision: 0.8295 - recall: 0.7164 - val_loss: 0.0622 - val_precision: 0.6793 - val_recall: 0.6365\n",
      "Epoch 8/12\n",
      "159528/159528 [==============================] - 1184s 7ms/step - loss: 0.0387 - precision: 0.8354 - recall: 0.7269 - val_loss: 0.0631 - val_precision: 0.6797 - val_recall: 0.6303\n",
      "Epoch 9/12\n",
      "159528/159528 [==============================] - 1222s 8ms/step - loss: 0.0374 - precision: 0.8371 - recall: 0.7380 - val_loss: 0.0643 - val_precision: 0.6519 - val_recall: 0.6688\n",
      "Epoch 10/12\n",
      "159528/159528 [==============================] - 1196s 7ms/step - loss: 0.0359 - precision: 0.8397 - recall: 0.7489 - val_loss: 0.0649 - val_precision: 0.6634 - val_recall: 0.6624\n",
      "Epoch 11/12\n",
      "159528/159528 [==============================] - 1225s 8ms/step - loss: 0.0344 - precision: 0.8435 - recall: 0.7614 - val_loss: 0.0664 - val_precision: 0.6590 - val_recall: 0.6682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x199ba5ba950>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build model\n",
    "learning_rate = 1e-3\n",
    "my_sgd = optimizers.SGD(learning_rate=learning_rate, decay=0.0, momentum=0.9)\n",
    "\n",
    "i = Input((None, 300))\n",
    "\n",
    "conv1 = Conv1D(128, kernel_size=1, padding='valid', activation='relu')(i)\n",
    "conv2 = Conv1D(256, kernel_size=2, padding='same', activation='relu')(conv1)\n",
    "conv3 = Conv1D(512, kernel_size=3, strides=2, padding='same', activation='relu')(conv2)\n",
    "pool = GlobalMaxPooling1D()(conv3)\n",
    "drop = Dropout(0.25)(pool)\n",
    "\n",
    "d = Dense(400, activation='relu')(drop)\n",
    "drop2 = Dropout(0.25)(d)\n",
    "\n",
    "o = Dense(6, activation='sigmoid')(drop2)\n",
    "\n",
    "New_CNN = Model(i, o)\n",
    "\n",
    "New_CNN.compile(loss='binary_crossentropy', optimizer=my_sgd, metrics=['Precision', 'Recall'])\n",
    "\n",
    "def generate_inputs():\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for pair in zip(train_text, train_labels):\n",
    "            x_train = pair[0].reshape(1, pair[0].shape[0], 300)\n",
    "            y_train = pair[1].reshape(1, 6)\n",
    "            yield x_train, y_train\n",
    "\n",
    "def generate_vals():\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for pair in zip(val_text, val_labels):\n",
    "            x_val = pair[0].reshape(1, pair[0].shape[0], 300)\n",
    "            y_val = pair[1].reshape(1, 6)\n",
    "            yield x_val, y_val\n",
    "            \n",
    "#train_model\n",
    "train_steps = len(train_labels)\n",
    "val_steps = len(val_labels)\n",
    "New_CNN.fit(generate_inputs(), steps_per_epoch=train_steps, verbose=1, epochs=12, \n",
    "            validation_data=generate_vals(), validation_steps=val_steps, callbacks=[stop_callback])\n",
    "#New_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_CNN.save(\"C:/Users/gande/Desktop/ProjektKlassifikation/New_toxic_CNN_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_predictions(x_test, model):\n",
    "\n",
    "    predarr = np.zeros(6).reshape(1, 6)\n",
    "\n",
    "    for idx, x in enumerate(x_test):\n",
    "        comment = x.reshape(1, x.shape[0], 300)\n",
    "        prediction = np.round(model.predict(comment, steps=1, verbose=0))\n",
    "        predarr = np.concatenate((predarr, prediction)) \n",
    "        #print(f\"Prediction {idx} done\")\n",
    "    \n",
    "    y_pred = predarr[1:]\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = all_predictions(test_text, New_CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6628546602613343"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weighted macro-averaged precision\n",
    "prec_weighted = precision_score(test_labels, y_pred, average=\"weighted\")\n",
    "prec_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6483709612004867"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#micro-averaged\n",
    "prec_micro = precision_score(test_labels, y_pred, average='micro')\n",
    "prec_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627971254836926"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weighted macro-averaged recall\n",
    "rec_weighted = recall_score(test_labels, y_pred, average='weighted')\n",
    "rec_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627971254836926"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#micro-averaged recall\n",
    "rec_micro = recall_score(test_labels, y_pred, average='micro')\n",
    "rec_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6446679633629855"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weighted macro-averaged F1 score\n",
    "f1_weighted = f1_score(test_labels, y_pred, average=\"weighted\")\n",
    "f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6555046812000273"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#micro-averaged F1 score\n",
    "f1_mic = f1_score(test_labels, y_pred, average='micro')\n",
    "f1_mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
